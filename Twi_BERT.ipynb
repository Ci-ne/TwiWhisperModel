{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Environment setup and installations"
      ],
      "metadata": {
        "id": "iLoOOtJN01LK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "id": "FP9SwIMiP3Ss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2e02c1a-f5b0-42e9-da90-961491083371",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-68pp50wt\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-68pp50wt\n",
            "  Resolved https://github.com/openai/whisper.git to commit 90db0de1896c23cbfaf0c58bc2d30665f709f170\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (4.66.6)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (10.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.8.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper==20240930) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets tokenizers\n",
        "import io\n",
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "import pandas as pd\n",
        "import torch\n",
        "import whisper\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM, pipeline\n",
        "# Load the BERT model and tokenizer for corrections\n",
        "from transformers import BertTokenizer, BertForMaskedLM, pipeline"
      ],
      "metadata": {
        "id": "TqPPie2X08MH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e80410ea-137c-49cb-f9e4-afbbd4c518d1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjU2v_ABiPHP",
        "outputId": "0548de09-f76d-4cb4-9208-417b8dc5b354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading data"
      ],
      "metadata": {
        "id": "59wlFVMWb8BZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AsantiTwiDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, zip_url, csv_filename, audio_base_path, processor=None, device=\"cpu\"):\n",
        "        self.device = device\n",
        "        self.audio_base_path = audio_base_path\n",
        "        self.processor = processor\n",
        "\n",
        "        # Download and extract the dataset\n",
        "        response = requests.get(zip_url, stream=True)\n",
        "        response.raise_for_status()\n",
        "        with zipfile.ZipFile(io.BytesIO(response.content), 'r') as zip_ref:\n",
        "            zip_ref.extractall('.')\n",
        "\n",
        "        # Clean the CSV file\n",
        "        cleaned_csv_filename = f\"cleaned_{os.path.basename(csv_filename)}\"\n",
        "        self.clean_csv(csv_filename, cleaned_csv_filename)\n",
        "\n",
        "        # Load the cleaned CSV\n",
        "        self.df = pd.read_csv(cleaned_csv_filename)\n",
        "\n",
        "        # Map columns if needed\n",
        "        column_mapping = {\n",
        "            \"Audio Filepath\": \"path\",\n",
        "            \"Transcription\": \"sentence\",\n",
        "        }\n",
        "        self.df.rename(columns=lambda x: column_mapping.get(x.strip(), x.strip()), inplace=True)\n",
        "\n",
        "        # Verify required columns\n",
        "        if 'path' not in self.df.columns or 'sentence' not in self.df.columns:\n",
        "            raise ValueError(\"CSV file must contain 'path' and 'sentence' columns.\")\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Returns a single data item at a given index.\"\"\"\n",
        "        # Get the row from the DataFrame\n",
        "        row = self.df.iloc[index]\n",
        "\n",
        "        # Construct the audio file path\n",
        "        audio_path = os.path.join(self.audio_base_path, row['path'])\n",
        "\n",
        "        # Get the corresponding sentence\n",
        "        sentence = row['sentence']\n",
        "\n",
        "        # Return a dictionary containing the audio path and sentence\n",
        "        return {'audio_path': audio_path, 'sentence': sentence}\n",
        "\n",
        "    @staticmethod\n",
        "    def clean_csv(input_path, output_path):\n",
        "        \"\"\"\n",
        "        Cleans a CSV file by:\n",
        "        - Replacing tab characters with commas.\n",
        "        - Filtering rows with inconsistent numbers of fields.\n",
        "        \"\"\"\n",
        "        with open(input_path, \"r\") as infile:\n",
        "            lines = infile.readlines()\n",
        "\n",
        "        # Replace tabs with commas\n",
        "        clean_lines = [line.replace(\"\\t\", \",\").replace(\"lacuna-audios-train/asanti-twi/audios/\", \"\").replace(\"lacuna-audios-test/asanti-twi/audios/\", \"\") for line in lines]\n",
        "\n",
        "        # Filter rows with the correct number of fields\n",
        "        expected_fields = clean_lines[0].count(\",\") + 1\n",
        "        valid_lines = [line for line in clean_lines if line.count(\",\") + 1 == expected_fields]\n",
        "\n",
        "        # Write cleaned content to a new file\n",
        "        with open(output_path, \"w\") as outfile:\n",
        "            outfile.writelines(valid_lines)\n",
        "\n",
        "\n",
        "# Dataset URLs and paths\n",
        "train_zip_url = \"https://fisd-dataset.s3.amazonaws.com/fisd-asanti-twi-90p.zip\"\n",
        "train_csv_filename = \"fisd-asanti-twi-90p/data.csv\"\n",
        "train_audio_base_path = \"fisd-asanti-twi-90p/audios\"\n",
        "\n",
        "test_zip_url = \"https://fisd-dataset.s3.amazonaws.com/fisd-asanti-twi-10p.zip\"\n",
        "test_csv_filename = \"fisd-asanti-twi-10p/data.csv\"\n",
        "test_audio_base_path = \"fisd-asanti-twi-10p/audios\"\n",
        "\n",
        "# Load datasets\n",
        "test_dataset = AsantiTwiDataset(test_zip_url, test_csv_filename, test_audio_base_path)\n",
        "train_dataset = AsantiTwiDataset(train_zip_url, train_csv_filename, train_audio_base_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "j7j2v6_9srWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testinglabels = \"/content/drive/MyDrive/ABENA_Trained/Testlabels.csv\"\n",
        "df = pd.read_csv(testinglabels, delimiter=\"\\t\", names=[\"Index\", \"path\",\"sentence\",\"translation\"], header=0)\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "id": "5RGGX-dmtMeg",
        "outputId": "93450db5-c329-4a31-8a30-c0df937765bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Index                                               path  \\\n",
              "0   31861  lacuna-audios-test/asanti-twi/audios/AsantiTwi...   \n",
              "1   31862  lacuna-audios-test/asanti-twi/audios/AsantiTwi...   \n",
              "2   31863  lacuna-audios-test/asanti-twi/audios/AsantiTwi...   \n",
              "3   31864  lacuna-audios-test/asanti-twi/audios/AsantiTwi...   \n",
              "4   31865  lacuna-audios-test/asanti-twi/audios/AsantiTwi...   \n",
              "5   31866  lacuna-audios-test/asanti-twi/audios/AsantiTwi...   \n",
              "6   31867  lacuna-audios-test/asanti-twi/audios/AsantiTwi...   \n",
              "7   31868  lacuna-audios-test/asanti-twi/audios/AsantiTwi...   \n",
              "8   31869  lacuna-audios-test/asanti-twi/audios/AsantiTwi...   \n",
              "9   31870  lacuna-audios-test/asanti-twi/audios/AsantiTwi...   \n",
              "10  31871  lacuna-audios-test/asanti-twi/audios/AsantiTwi...   \n",
              "11  31872  lacuna-audios-test/asanti-twi/audios/AsantiTwi...   \n",
              "12  31873  lacuna-audios-test/asanti-twi/audios/AsantiTwi...   \n",
              "13  31874  lacuna-audios-test/asanti-twi/audios/AsantiTwi...   \n",
              "14  31875  lacuna-audios-test/asanti-twi/audios/AsantiTwi...   \n",
              "15  31876  lacuna-audios-test/asanti-twi/audios/AsantiTwi...   \n",
              "16  31877  lacuna-audios-test/asanti-twi/audios/AsantiTwi...   \n",
              "17  31878  lacuna-audios-test/asanti-twi/audios/AsantiTwi...   \n",
              "18  31879  lacuna-audios-test/asanti-twi/audios/AsantiTwi...   \n",
              "\n",
              "                                    sentence  \\\n",
              "0                          Fa thousand ma me   \n",
              "1   Tsɔrɔ phone number wei ma me: 0548992233   \n",
              "2                            Wanma me ntosoɔ   \n",
              "3   Tsɔrɔ phone number wei ma me: 0278759823   \n",
              "4   Fa ma ne phone number wei so: 0258934896   \n",
              "5             Mepaa'kyɛw me number no yɛ 020   \n",
              "6              MƐ tɔ Telecel credit 20 cedis   \n",
              "7                            MƐ yɛ Tigo momo   \n",
              "8                             Ɔyɛ Burkina ba   \n",
              "9                                Nipa yɛ bad   \n",
              "10                        Hwɛ ni ti kɛseɛ bi   \n",
              "11                   Mepaa'kyɛw me ndi prɛko   \n",
              "12                                   Telecel   \n",
              "13                           Mɛgye no ɛkyena   \n",
              "14                              Kwame ne Ama   \n",
              "15                                Woho yɛ fɛ   \n",
              "16                    Mesuro sɛ mesika bɛ sa   \n",
              "17                       Nti ɔtɔɔ quarter bi   \n",
              "18                      Mɛ tɔ brodo 10 cedis   \n",
              "\n",
              "                                   translation  \n",
              "0                                 Give me 1000  \n",
              "1   Write this phone number for me: 0548992233  \n",
              "2                    You did not give me bonus  \n",
              "3   Write this phone number for me: 0278759823  \n",
              "4    Send it to me on this number:  0258934896  \n",
              "5                      Please my number is 020  \n",
              "6           I will buy 20 cedis Telecel credit  \n",
              "7                          I will do Tigo momo  \n",
              "8                            He is a burkinabe  \n",
              "9                               People are bad  \n",
              "10                        Look at his big head  \n",
              "11                     Please I do not eat pig  \n",
              "12                                     Telecel  \n",
              "13                     I will take it tomorrow  \n",
              "14                               Kwame and Ama  \n",
              "15                           You are beautiful  \n",
              "16      I am afraid my money will get finished  \n",
              "17              So he bought just some quarter  \n",
              "18                     I bought bread 10 cedis  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5bf6fde1-3d0f-4f6c-9388-d6e9b943beb3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>path</th>\n",
              "      <th>sentence</th>\n",
              "      <th>translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31861</td>\n",
              "      <td>lacuna-audios-test/asanti-twi/audios/AsantiTwi...</td>\n",
              "      <td>Fa thousand ma me</td>\n",
              "      <td>Give me 1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31862</td>\n",
              "      <td>lacuna-audios-test/asanti-twi/audios/AsantiTwi...</td>\n",
              "      <td>Tsɔrɔ phone number wei ma me: 0548992233</td>\n",
              "      <td>Write this phone number for me: 0548992233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31863</td>\n",
              "      <td>lacuna-audios-test/asanti-twi/audios/AsantiTwi...</td>\n",
              "      <td>Wanma me ntosoɔ</td>\n",
              "      <td>You did not give me bonus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31864</td>\n",
              "      <td>lacuna-audios-test/asanti-twi/audios/AsantiTwi...</td>\n",
              "      <td>Tsɔrɔ phone number wei ma me: 0278759823</td>\n",
              "      <td>Write this phone number for me: 0278759823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31865</td>\n",
              "      <td>lacuna-audios-test/asanti-twi/audios/AsantiTwi...</td>\n",
              "      <td>Fa ma ne phone number wei so: 0258934896</td>\n",
              "      <td>Send it to me on this number:  0258934896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>31866</td>\n",
              "      <td>lacuna-audios-test/asanti-twi/audios/AsantiTwi...</td>\n",
              "      <td>Mepaa'kyɛw me number no yɛ 020</td>\n",
              "      <td>Please my number is 020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>31867</td>\n",
              "      <td>lacuna-audios-test/asanti-twi/audios/AsantiTwi...</td>\n",
              "      <td>MƐ tɔ Telecel credit 20 cedis</td>\n",
              "      <td>I will buy 20 cedis Telecel credit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>31868</td>\n",
              "      <td>lacuna-audios-test/asanti-twi/audios/AsantiTwi...</td>\n",
              "      <td>MƐ yɛ Tigo momo</td>\n",
              "      <td>I will do Tigo momo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>31869</td>\n",
              "      <td>lacuna-audios-test/asanti-twi/audios/AsantiTwi...</td>\n",
              "      <td>Ɔyɛ Burkina ba</td>\n",
              "      <td>He is a burkinabe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>31870</td>\n",
              "      <td>lacuna-audios-test/asanti-twi/audios/AsantiTwi...</td>\n",
              "      <td>Nipa yɛ bad</td>\n",
              "      <td>People are bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>31871</td>\n",
              "      <td>lacuna-audios-test/asanti-twi/audios/AsantiTwi...</td>\n",
              "      <td>Hwɛ ni ti kɛseɛ bi</td>\n",
              "      <td>Look at his big head</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>31872</td>\n",
              "      <td>lacuna-audios-test/asanti-twi/audios/AsantiTwi...</td>\n",
              "      <td>Mepaa'kyɛw me ndi prɛko</td>\n",
              "      <td>Please I do not eat pig</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>31873</td>\n",
              "      <td>lacuna-audios-test/asanti-twi/audios/AsantiTwi...</td>\n",
              "      <td>Telecel</td>\n",
              "      <td>Telecel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>31874</td>\n",
              "      <td>lacuna-audios-test/asanti-twi/audios/AsantiTwi...</td>\n",
              "      <td>Mɛgye no ɛkyena</td>\n",
              "      <td>I will take it tomorrow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>31875</td>\n",
              "      <td>lacuna-audios-test/asanti-twi/audios/AsantiTwi...</td>\n",
              "      <td>Kwame ne Ama</td>\n",
              "      <td>Kwame and Ama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>31876</td>\n",
              "      <td>lacuna-audios-test/asanti-twi/audios/AsantiTwi...</td>\n",
              "      <td>Woho yɛ fɛ</td>\n",
              "      <td>You are beautiful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>31877</td>\n",
              "      <td>lacuna-audios-test/asanti-twi/audios/AsantiTwi...</td>\n",
              "      <td>Mesuro sɛ mesika bɛ sa</td>\n",
              "      <td>I am afraid my money will get finished</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>31878</td>\n",
              "      <td>lacuna-audios-test/asanti-twi/audios/AsantiTwi...</td>\n",
              "      <td>Nti ɔtɔɔ quarter bi</td>\n",
              "      <td>So he bought just some quarter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>31879</td>\n",
              "      <td>lacuna-audios-test/asanti-twi/audios/AsantiTwi...</td>\n",
              "      <td>Mɛ tɔ brodo 10 cedis</td>\n",
              "      <td>I bought bread 10 cedis</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5bf6fde1-3d0f-4f6c-9388-d6e9b943beb3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5bf6fde1-3d0f-4f6c-9388-d6e9b943beb3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5bf6fde1-3d0f-4f6c-9388-d6e9b943beb3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0dbe1023-bcc1-4794-a08a-eea79e0f7584\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0dbe1023-bcc1-4794-a08a-eea79e0f7584')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0dbe1023-bcc1-4794-a08a-eea79e0f7584 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3a26c930-3c5a-4cff-a533-b7dfbeb365b1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3a26c930-3c5a-4cff-a533-b7dfbeb365b1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 19,\n  \"fields\": [\n    {\n      \"column\": \"Index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 31861,\n        \"max\": 31879,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          31861,\n          31866,\n          31872\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"lacuna-audios-test/asanti-twi/audios/AsantiTwiFm21-gEvrpCyP-Tmp002-5Njp97.ogg\",\n          \"lacuna-audios-test/asanti-twi/audios/AsantiTwiFm21-gEvrpCyP-Tmp007-5Njp97.ogg\",\n          \"lacuna-audios-test/asanti-twi/audios/AsantiTwiFm21-gEvrpCyP-Tmp013-5Njp97.ogg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"Fa thousand ma me\",\n          \"Mepaa'ky\\u025bw me number no y\\u025b 020\",\n          \"Mepaa'ky\\u025bw me ndi pr\\u025bko\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"translation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"Give me 1000\",\n          \"Please my number is 020\",\n          \"Please I do not eat pig\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions to use BERT Model"
      ],
      "metadata": {
        "id": "YsXzfRBSb_3E"
      }
    },
    {
      "source": [
        "import transformers.pipelines.pt_utils\n",
        "def correct_asr_output(text):\n",
        "\n",
        "    masked_text = text + \" [MASK]\"  # Add the mask token at the end\n",
        "    corrected_text = corrector_robako(masked_text)\n",
        "    corrected_word = corrected_text[0]['token_str']\n",
        "    corrected_sentence = masked_text.replace(\"[MASK]\", corrected_word)\n",
        "\n",
        "    corrected_sequence = corrected_sentence.replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
        "    # Extract the predicted token (ignoring the original input and [MASK])\n",
        "    return corrected_sequence[0][0]\n",
        "\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    # Pass options as keyword arguments within transcribe\n",
        "    model = whisper.load_model(\"tiny\")\n",
        "    result = model.transcribe(audio_path, language=\"en\", without_timestamps=True)\n",
        "    return result['text']"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "J7-Thl5Dyvhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Example usage for selecting a random statement\n",
        "import random\n",
        "import os\n",
        "\n",
        "\n",
        "# Select a random index within the dataset\n",
        "random_index = random.randint(0, len(test_dataset) - 1)\n",
        "\n",
        "# Get the data item at the random index\n",
        "random_item = test_dataset[random_index]\n",
        "\n",
        "# Access the audio path and sentence from the random item\n",
        "audio_path = random_item['audio_path']\n",
        "sentence = random_item['sentence']\n",
        "\n",
        "print(\"Random Audio Path:\", audio_path)\n",
        "print(\"Random Sentence:\", sentence)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"Some weights of the model checkpoint\") #Was flooding the output\n",
        "\n",
        "# Transcribe and correct the random audio\n",
        "asr_output = transcribe_audio(audio_path)\n",
        "print(\"ASR Output:\", asr_output)\n",
        "\n",
        "# Load the BERT Abena model for correction\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM, pipeline\n",
        "\n",
        "tokenizer_abena = AutoTokenizer.from_pretrained(\"Ghana-NLP/abena-base-asante-twi-uncased\")\n",
        "corrector_model_abena = AutoModelForMaskedLM.from_pretrained(\"Ghana-NLP/abena-base-asante-twi-uncased\")\n",
        "corrector_abena = pipeline(\"fill-mask\", model=corrector_model_abena, tokenizer=tokenizer_abena, device=0)\n",
        "\n",
        "# Correct ASR output using Abena\n",
        "corrected_output_abena = corrector_abena(asr_output.replace(\" \", \" [MASK] \"))\n",
        "print(\"Corrected Output (Abena):\", corrected_output_abena)\n",
        "print(\"\\n\\n\\n\")\n",
        "\n",
        "# Load the BERT Robako model for correction\n",
        "tokenizer_robako = AutoTokenizer.from_pretrained(\"Ghana-NLP/robako-base-asante-twi-uncased\")\n",
        "corrector_model_robako = AutoModelForMaskedLM.from_pretrained(\"Ghana-NLP/robako-base-asante-twi-uncased\")\n",
        "corrector_robako = pipeline(task = \"fill-mask\", model=corrector_model_robako, tokenizer=tokenizer_robako, device=0)\n",
        "\n",
        "# Correct ASR output using Robako\n",
        "#loads of errors here while trying to extract just the sentence, so tried different ways to get just the output\n",
        "#masked_texts = [correct_asr_output(text) for text in asr_output.split()]\n",
        "#corrected_output_robako = [corrector_robako(text)[0]['token_str'] for text in asr_output.split()]\n",
        "#corrected_output_robako = \" \".join(corrected_output_robako)\n",
        "#corrected_output_robako = [corrector_robako(text + \" [MASK]\")[0]['token_str'] for text in asr_output.split()]\n",
        "corrected_output_robako = [corrector_robako(text + \" <mask>\")[0]['sequence'] for text in asr_output.split()]\n",
        "corrected_output_robako = \" \".join(corrected_output_robako)\n",
        "print(\"Corrected Output (Robako):\", corrected_output_robako)\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "0XtMzbqF413L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd023a0-b1ff-4187-9624-fa50f01b1bd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Audio Path: fisd-asanti-twi-10p/audios/AsantiTwiFm18-NNYuf3Ef-Tmp128-DWSA5F.ogg\n",
            "Random Sentence: Nsu kɔm de me\n",
            "ASR Output:  interviewed people with\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at Ghana-NLP/abena-base-asante-twi-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrected Output (Abena): [[{'score': 0.058371469378471375, 'token': 12888, 'token_str': 'see', 'sequence': '[CLS] see interviewed [MASK] people [MASK] with [SEP]'}, {'score': 0.040831975638866425, 'token': 10114, 'token_str': 'to', 'sequence': '[CLS] to interviewed [MASK] people [MASK] with [SEP]'}, {'score': 0.03652362897992134, 'token': 10132, 'token_str': 'na', 'sequence': '[CLS] na interviewed [MASK] people [MASK] with [SEP]'}, {'score': 0.021701844409108162, 'token': 10428, 'token_str': 'met', 'sequence': '[CLS] met interviewed [MASK] people [MASK] with [SEP]'}, {'score': 0.02074621431529522, 'token': 10135, 'token_str': 'on', 'sequence': '[CLS] on interviewed [MASK] people [MASK] with [SEP]'}], [{'score': 0.10930045694112778, 'token': 10108, 'token_str': 'of', 'sequence': '[CLS] [MASK] interviewed of people [MASK] with [SEP]'}, {'score': 0.07340721040964127, 'token': 10114, 'token_str': 'to', 'sequence': '[CLS] [MASK] interviewed to people [MASK] with [SEP]'}, {'score': 0.042703963816165924, 'token': 10135, 'token_str': 'on', 'sequence': '[CLS] [MASK] interviewed on people [MASK] with [SEP]'}, {'score': 0.03378722071647644, 'token': 10142, 'token_str': 'for', 'sequence': '[CLS] [MASK] interviewed for people [MASK] with [SEP]'}, {'score': 0.01733122393488884, 'token': 169, 'token_str': 'a', 'sequence': '[CLS] [MASK] interviewed a people [MASK] with [SEP]'}], [{'score': 0.1565569043159485, 'token': 10108, 'token_str': 'of', 'sequence': '[CLS] [MASK] interviewed [MASK] people of with [SEP]'}, {'score': 0.12106943875551224, 'token': 10114, 'token_str': 'to', 'sequence': '[CLS] [MASK] interviewed [MASK] people to with [SEP]'}, {'score': 0.00960386823862791, 'token': 10142, 'token_str': 'for', 'sequence': '[CLS] [MASK] interviewed [MASK] people for with [SEP]'}, {'score': 0.00955392699688673, 'token': 131, 'token_str': ':', 'sequence': '[CLS] [MASK] interviewed [MASK] people : with [SEP]'}, {'score': 0.006974663585424423, 'token': 10111, 'token_str': 'and', 'sequence': '[CLS] [MASK] interviewed [MASK] people and with [SEP]'}]]\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at Ghana-NLP/robako-base-asante-twi-uncased were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrected Output (Robako): interviewedt people mma with mu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using BERT to correct errors"
      ],
      "metadata": {
        "id": "jsMPfOSQMSBV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgyCcyr6m3-o"
      },
      "source": [
        "## Method 1: Language Modelling\n",
        "Trying to use predicting the next work to correct it (later figured out it was not a meaningful way to get things done)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egak1_OZnCkt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652,
          "referenced_widgets": [
            "1fa16808e2c54b998437e47d1b520f3d",
            "f08bcc15e97d4e2fa9ed85a0159404c5",
            "df51169e8b4843ef8f668633ad48b6d6",
            "3209b39cfd0a4c06a32c4678656695cd",
            "b2b69288b7964da6b2b84f565d557b78",
            "0c4a2f71b71d48b5bec4e78068386c1e",
            "0706c1224c2e4534af8fd4f82485c366",
            "ac6930c9dc4d41eaa64818d880317776",
            "897764c7f53b4ae5acb492c77c25111e",
            "e06e47c8ddcc4ddabbade286d601cdde",
            "6e876ebd5a2f46999cbd2633afe0e857"
          ]
        },
        "outputId": "f4c86e9c-06e7-45f9-d847-21a615254b6d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fa16808e2c54b998437e47d1b520f3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/26332 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at Ghana-NLP/abena-base-asante-twi-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5269' max='7902' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5269/7902 1:13:32 < 36:45, 1.19 it/s, Epoch 4/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.320800</td>\n",
              "      <td>0.110830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.079900</td>\n",
              "      <td>0.072430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.049800</td>\n",
              "      <td>0.055899</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='107' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [107/330 00:26 < 00:55, 4.04 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7902' max='7902' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7902/7902 1:49:20, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.320800</td>\n",
              "      <td>0.110830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.079900</td>\n",
              "      <td>0.072430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.049800</td>\n",
              "      <td>0.055899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.035800</td>\n",
              "      <td>0.054562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.027900</td>\n",
              "      <td>0.062772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.027100</td>\n",
              "      <td>0.057901</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/ABENA_Trained2/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/ABENA_Trained2/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/ABENA_Trained2/vocab.txt',\n",
              " '/content/drive/MyDrive/ABENA_Trained2/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#for language modelling\n",
        "\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import BertTokenizer, BertForMaskedLM, Trainer, TrainingArguments\n",
        "\n",
        "\n",
        "dataset = Dataset.from_pandas(train_dataset.df)\n",
        "#dataset = Dataset.from_pandas(test_dataset)\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"Ghana-NLP/abena-base-asante-twi-uncased\")\n",
        "\n",
        "# Tokenize the dataset\n",
        "'''def tokenize_function(examples):\n",
        "    # Specifying max_length here ensures all sequences are the same length\n",
        "    return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True, max_length=128) # Added max_length'''\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    # Specifying max_length here ensures all sequences are the same length\n",
        "    # Create labels by replacing masked tokens with -100 (ignore index)\n",
        "    inputs = tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")  # Added max_length, return_tensors=\"pt\"\n",
        "    inputs[\"labels\"] = inputs.input_ids.detach().clone()\n",
        "    # create random array of floats with equal dims to input_ids\n",
        "    rand = torch.rand(inputs.input_ids.shape)\n",
        "    # mask random 15% where token is not 0 [PAD], 1 [CLS], or 2 [SEP]\n",
        "    mask_arr = (rand < 0.15) * (inputs.input_ids != 0) * (inputs.input_ids != 1) * (inputs.input_ids != 2)\n",
        "    # loop through each row in input_ids tensor (cannot do in parallel)\n",
        "    for i in range(inputs.input_ids.shape[0]):\n",
        "        # get indices of mask positions from mask array\n",
        "        selection = torch.flatten(mask_arr[i].nonzero()).tolist()\n",
        "        # mask input_ids\n",
        "        inputs.input_ids[i, selection] = tokenizer.mask_token_id\n",
        "    # where input_ids is not masked, set labels to -100\n",
        "    inputs[\"labels\"][~mask_arr] = -100\n",
        "\n",
        "    return inputs\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.train_test_split(test_size=0.2)\n",
        "\n",
        "# Load the model\n",
        "model = BertForMaskedLM.from_pretrained(\"Ghana-NLP/abena-base-asante-twi-uncased\")\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=6,\n",
        "    weight_decay=0.01,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "trainer.save_model(\"/content/drive/MyDrive/ABENA_Trained2\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/ABENA_Trained2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"/content/drive/MyDrive/ABENA_Trained\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/ABENA_Trained\")"
      ],
      "metadata": {
        "id": "qHA3CIsgicxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM, pipeline\n",
        "\n",
        "# Load your fine-tuned model and tokenizer\n",
        "model_path = \"/content/drive/MyDrive/ABENA_Trained\"  # Update with your save path\n",
        "\n",
        "# Load the tokenizer from the configuration file\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Load the model, potentially specifying the safetensors file\n",
        "model = BertForMaskedLM.from_pretrained(model_path, torch_dtype=\"auto\")\n",
        "\n",
        "# Create a fill-mask pipeline\n",
        "fill_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Test with a sentence\n",
        "test_sentence = \"Mɛtumi ayɛ [MASK] million cedis.\"\n",
        "predictions = fill_mask(test_sentence)\n",
        "\n",
        "# Print the predictions\n",
        "for prediction in predictions:\n",
        "    print(f\"Predicted word: {prediction['token_str']}, Score: {prediction['score']:.4f}\")\n",
        "\n",
        "\n",
        "# Print only the predicted word\n",
        "predicted_word = predictions[0]['token_str']\n",
        "print(f\"Predicted sentence: {test_sentence.replace('[MASK]', predicted_word)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0cN8aFOkHnl",
        "outputId": "de76acdf-c957-4494-fe2c-66756f9dd63b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted word: credit, Score: 0.9863\n",
            "Predicted word: transfer, Score: 0.0032\n",
            "Predicted word: fi, Score: 0.0022\n",
            "Predicted word: 5, Score: 0.0007\n",
            "Predicted word: aka, Score: 0.0006\n",
            "Predicted sentence: Mɛtumi ayɛ credit million cedis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "def mask_random_word(sentence):\n",
        "    \"\"\"Masks a single random word in a sentence.\n",
        "\n",
        "    Args:\n",
        "        sentence (str): The input sentence.\n",
        "\n",
        "    Returns:\n",
        "        str: The sentence with one word randomly masked.\n",
        "    \"\"\"\n",
        "    words = sentence.split()\n",
        "    if words:  # Check if the sentence is not empty\n",
        "        random_index = random.randint(0, len(words) - 1)  # Get a random index\n",
        "        words[random_index] = \"[MASK]\"  # Replace the word at that index\n",
        "    return \" \".join(words)  # Join the words back into a sentence"
      ],
      "metadata": {
        "id": "dPPsrrVCvleL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # If using a CSV file\n",
        "from transformers import BertTokenizer, BertForMaskedLM, pipeline\n",
        "\n",
        "# Load fine-tuned model and tokenizer\n",
        "model_path = \"/content/drive/MyDrive/ABENA_Trained\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "model = BertForMaskedLM.from_pretrained(model_path)\n",
        "fill_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "\n",
        "testinglabels = \"/content/drive/MyDrive/ABENA_Trained2/Testlabels.csv\"\n",
        "df = pd.read_csv(testinglabels, delimiter=\"\\t\", names=[\"Index\", \"path\",\"sentence\",\"translation\"], header=0)\n",
        "df[\"masked_sentence\"] = df[\"sentence\"].apply(mask_random_word)\n",
        "\n",
        "\n",
        "# Prediction loop\n",
        "#for sentence in sentences:\n",
        "for index, row in df.iterrows():\n",
        "    # Replace a word with [MASK] for prediction\n",
        "    masked_sentence = row[\"masked_sentence\"]\n",
        "    predictions = fill_mask(masked_sentence)\n",
        "    #masked_sentence = sentence.replace(\"target_word\", \"[MASK]\")\n",
        "    #predictions = fill_mask(masked_sentence)\n",
        "    predicted_word = predictions[0]['token_str']  # Get the top prediction\n",
        "\n",
        "    # Compare predicted word with actual word\n",
        "    print(f\"Original Sentence: {row['sentence']}\")\n",
        "    print(f\"Masked Sentence: {masked_sentence}\")\n",
        "    print(f\"Predicted Word: {predicted_word}\")\n",
        "    print(f\"Predicted Sentence: {masked_sentence.replace('[MASK]', predicted_word)}\")\n",
        "    print(\"-\" * 20)  # Separator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYlXzdD5rE7O",
        "outputId": "2a8365ac-6485-4880-b690-772091c02925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence: Fa thousand ma me\n",
            "Masked Sentence: [MASK] thousand ma me\n",
            "Predicted Word: to\n",
            "Predicted Sentence: to thousand ma me\n",
            "--------------------\n",
            "Original Sentence: Tsɔrɔ phone number wei ma me: 0548992233\n",
            "Masked Sentence: [MASK] phone number wei ma me: 0548992233\n",
            "Predicted Word: me\n",
            "Predicted Sentence: me phone number wei ma me: 0548992233\n",
            "--------------------\n",
            "Original Sentence: Wanma me ntosoɔ\n",
            "Masked Sentence: Wanma me [MASK]\n",
            "Predicted Word: bi\n",
            "Predicted Sentence: Wanma me bi\n",
            "--------------------\n",
            "Original Sentence: Tsɔrɔ phone number wei ma me: 0278759823\n",
            "Masked Sentence: Tsɔrɔ phone [MASK] wei ma me: 0278759823\n",
            "Predicted Word: number\n",
            "Predicted Sentence: Tsɔrɔ phone number wei ma me: 0278759823\n",
            "--------------------\n",
            "Original Sentence: Fa ma ne phone number wei so: 0258934896\n",
            "Masked Sentence: Fa ma ne [MASK] number wei so: 0258934896\n",
            "Predicted Word: number\n",
            "Predicted Sentence: Fa ma ne number number wei so: 0258934896\n",
            "--------------------\n",
            "Original Sentence: Mepaa'kyɛw me number no yɛ 020\n",
            "Masked Sentence: Mepaa'kyɛw [MASK] number no yɛ 020\n",
            "Predicted Word: me\n",
            "Predicted Sentence: Mepaa'kyɛw me number no yɛ 020\n",
            "--------------------\n",
            "Original Sentence: MƐ tɔ Telecel credit 20 cedis\n",
            "Masked Sentence: MƐ [MASK] Telecel credit 20 cedis\n",
            "Predicted Word: ##di\n",
            "Predicted Sentence: MƐ ##di Telecel credit 20 cedis\n",
            "--------------------\n",
            "Original Sentence: MƐ yɛ Tigo momo\n",
            "Masked Sentence: [MASK] yɛ Tigo momo\n",
            "Predicted Word: mee\n",
            "Predicted Sentence: mee yɛ Tigo momo\n",
            "--------------------\n",
            "Original Sentence: Ɔyɛ Burkina ba\n",
            "Masked Sentence: Ɔyɛ Burkina [MASK]\n",
            "Predicted Word: wei\n",
            "Predicted Sentence: Ɔyɛ Burkina wei\n",
            "--------------------\n",
            "Original Sentence: Nipa yɛ bad\n",
            "Masked Sentence: Nipa yɛ [MASK]\n",
            "Predicted Word: bad\n",
            "Predicted Sentence: Nipa yɛ bad\n",
            "--------------------\n",
            "Original Sentence: Hwɛ ni ti kɛseɛ bi\n",
            "Masked Sentence: Hwɛ ni ti kɛseɛ [MASK]\n",
            "Predicted Word: no\n",
            "Predicted Sentence: Hwɛ ni ti kɛseɛ no\n",
            "--------------------\n",
            "Original Sentence: Mepaa'kyɛw me ndi prɛko\n",
            "Masked Sentence: [MASK] me ndi prɛko\n",
            "Predicted Word: ma\n",
            "Predicted Sentence: ma me ndi prɛko\n",
            "--------------------\n",
            "Original Sentence: Telecel\n",
            "Masked Sentence: [MASK]\n",
            "Predicted Word: saa\n",
            "Predicted Sentence: saa\n",
            "--------------------\n",
            "Original Sentence: Mɛgye no ɛkyena\n",
            "Masked Sentence: [MASK] no ɛkyena\n",
            "Predicted Word: pia\n",
            "Predicted Sentence: pia no ɛkyena\n",
            "--------------------\n",
            "Original Sentence: Kwame ne Ama\n",
            "Masked Sentence: [MASK] ne Ama\n",
            "Predicted Word: credit\n",
            "Predicted Sentence: credit ne Ama\n",
            "--------------------\n",
            "Original Sentence: Woho yɛ fɛ\n",
            "Masked Sentence: [MASK] yɛ fɛ\n",
            "Predicted Word: ho\n",
            "Predicted Sentence: ho yɛ fɛ\n",
            "--------------------\n",
            "Original Sentence: Mesuro sɛ mesika bɛ sa\n",
            "Masked Sentence: Mesuro [MASK] mesika bɛ sa\n",
            "Predicted Word: ##u\n",
            "Predicted Sentence: Mesuro ##u mesika bɛ sa\n",
            "--------------------\n",
            "Original Sentence: Nti ɔtɔɔ quarter bi\n",
            "Masked Sentence: Nti [MASK] quarter bi\n",
            "Predicted Word: ma\n",
            "Predicted Sentence: Nti ma quarter bi\n",
            "--------------------\n",
            "Original Sentence: Mɛ tɔ brodo 10 cedis\n",
            "Masked Sentence: Mɛ tɔ brodo 10 [MASK]\n",
            "Predicted Word: credit\n",
            "Predicted Sentence: Mɛ tɔ brodo 10 credit\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Method 2: Text Correction\n",
        "This is the actual way to do correct the Whisper output, but had insufficient data for it. Was using the error data rom the finetuning of the whisper model on the financial inclusion dataset."
      ],
      "metadata": {
        "id": "kje-9Y6qiqDG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zR3LH6FMmxnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1df0711d-4111-42fe-d8f8-2ae295b58739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import BertTokenizer, EncoderDecoderModel, Trainer, TrainingArguments\n",
        "\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, pipeline\n",
        "\n",
        "# Load your fine-tuned model and tokenizer\n",
        "model_path = \"/content/drive/MyDrive/ABENA_Trained\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "model = BertForMaskedLM.from_pretrained(model_path)\n",
        "fill_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtZcLmzqmyOp"
      },
      "outputs": [],
      "source": [
        "testinglabels = \"/content/drive/MyDrive/ABENA_Trained/hypotheses_references.csv\"\n",
        "dataset = pd.read_csv(testinglabels, names=[\"Index\", \"path\",\"sentence\",\"translation\"], header=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers\n",
        "\n",
        "\n",
        "# Load a pre-trained BERT model for Asante Twi\n",
        "model_name = \"Ghana-NLP/abena-base-asante-twi-uncased\"  # Or \"Ghana-NLP/robako-base-asante-twi-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "\n",
        "fill_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Example test sentence\n",
        "test_sentence = \"Mɛtumi ayɛ [MASK] million cedis.\"\n",
        "predictions = fill_mask(test_sentence)\n",
        "print(f\"Predicted sentence: {test_sentence.replace('[MASK]', predictions[0]['token_str'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KEA03BSj9Ac",
        "outputId": "a5696333-4b49-4308-83d2-a8394c4224db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at Ghana-NLP/abena-base-asante-twi-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted sentence: Mɛtumi ayɛ le million cedis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "data_path = \"/content/drive/MyDrive/ABENA_Trained/hypotheses_references.csv\"\n",
        "df = pd.read_csv(data_path, names=[\"incorrect\", \"correct\", \"incorrect cleaned\", \"correct cleaned\"], header=0)\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "# Tokenization function\n",
        "def preprocess_function(examples):\n",
        "    # Use the 'incorrect cleaned' and 'correct cleaned' columns\n",
        "    inputs = tokenizer(examples[\"incorrect cleaned\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(examples[\"correct cleaned\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Split into train, validation, and test sets\n",
        "from datasets import DatasetDict # Import DatasetDict here\n",
        "train_testvalid = tokenized_datasets.train_test_split(test_size=0.2)\n",
        "test_valid = train_testvalid['test'].train_test_split(test_size=0.5)\n",
        "tokenized_datasets = DatasetDict({\n",
        "    'train': train_testvalid['train'],\n",
        "    'test': test_valid['test'],\n",
        "    'validation': test_valid['train']})\n",
        "\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit = 2, # Only last 2 models are saved. Older ones are deleted.\n",
        "    load_best_model_at_end=True,\n",
        "    save_strategy=\"epoch\",\n",
        "    report_to=\"none\",\n",
        "    logging_steps = 10\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "trainer.save_model(\"/content/drive/MyDrive/ABENA_FineTuned\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/ABENA_FineTuned\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466,
          "referenced_widgets": [
            "1e4224f1868b40d4a12baae5347b279a",
            "9ccf33920c7e43ef94a73e95ca7ffe30",
            "2e4493ed9dbc4cbbabe65e54d8051110",
            "f963715530a144f89d68eb8373265927",
            "ba12c07f21f9433c82e297dd1e4e9ce2",
            "37bab71f3586458b9ca74eea350e6c3f",
            "76e7386c692b4ea78d1b356bdab3d460",
            "2fe8c3ce54504519a6a30f17ed3b9422",
            "5bd69563899847e59544f5b2e0bb6c88",
            "b5ab558c92a24487b23b0e6968b6d3aa",
            "c469881d76744244ba79a8a8833dd5a4"
          ]
        },
        "id": "W2JWE4RQkB_U",
        "outputId": "d6cbdd84-94a8-41b2-ef01-f07a56a032d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/240 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e4224f1868b40d4a12baae5347b279a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4114: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 02:30, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>13.259800</td>\n",
              "      <td>8.824094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>7.977000</td>\n",
              "      <td>3.075538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.489000</td>\n",
              "      <td>1.138112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.379700</td>\n",
              "      <td>0.896338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.807200</td>\n",
              "      <td>0.827055</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/ABENA_FineTuned/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/ABENA_FineTuned/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/ABENA_FineTuned/vocab.txt',\n",
              " '/content/drive/MyDrive/ABENA_FineTuned/added_tokens.json',\n",
              " '/content/drive/MyDrive/ABENA_FineTuned/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM, pipeline\n",
        "\n",
        "# Load the fine-tuned model\n",
        "fine_tuned_tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/ABENA_FineTuned\")\n",
        "fine_tuned_model = AutoModelForMaskedLM.from_pretrained(\"/content/drive/MyDrive/ABENA_FineTuned\")\n",
        "\n",
        "corrector = pipeline(\"fill-mask\", model=fine_tuned_model, tokenizer=fine_tuned_tokenizer)\n",
        "\n",
        "def correct_text(text):\n",
        "    \"\"\"Corrects the input text using the fine-tuned model.\"\"\"\n",
        "    # Tokenize the input text\n",
        "    inputs = fine_tuned_tokenizer(text, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"][0]  # Access the first element of the tensor\n",
        "\n",
        "    # Create a copy of the input_ids to avoid modifying the original\n",
        "    masked_input_ids = input_ids.clone()\n",
        "\n",
        "    # Randomly mask 15% of the tokens (excluding special tokens)\n",
        "    rand = torch.rand(input_ids.shape)\n",
        "    mask_arr = (rand < 0.15) * (input_ids != fine_tuned_tokenizer.cls_token_id) * (input_ids != fine_tuned_tokenizer.sep_token_id)\n",
        "\n",
        "    # Apply the mask to the selected tokens\n",
        "    masked_input_ids[mask_arr] = fine_tuned_tokenizer.mask_token_id\n",
        "\n",
        "    # Run the model to predict the masked tokens\n",
        "    outputs = fine_tuned_model(masked_input_ids.unsqueeze(0))  # Add batch dimension\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "    # Decode the predicted tokens to get the corrected text\n",
        "    corrected_text = fine_tuned_tokenizer.decode(predictions[0], skip_special_tokens=True)\n",
        "\n",
        "    return corrected_text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiQ-L6SqkGu2",
        "outputId": "25099f16-a42a-4f63-983a-73d52b4c395e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "text_to_correct = \"Me den de Kwoku\"\n",
        "corrected_text = correct_text(text_to_correct)\n",
        "print(f\"Original Text: {text_to_correct}\")\n",
        "print(f\"Corrected Text: {corrected_text}\")"
      ],
      "metadata": {
        "id": "Z_VxrUIwuudr",
        "outputId": "c77816c9-2307-4883-dc83-b717fd5b3296",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: Me den de Kwoku\n",
            "Corrected Text: . meɛ denɛ woɛ\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1fa16808e2c54b998437e47d1b520f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f08bcc15e97d4e2fa9ed85a0159404c5",
              "IPY_MODEL_df51169e8b4843ef8f668633ad48b6d6",
              "IPY_MODEL_3209b39cfd0a4c06a32c4678656695cd"
            ],
            "layout": "IPY_MODEL_b2b69288b7964da6b2b84f565d557b78"
          }
        },
        "f08bcc15e97d4e2fa9ed85a0159404c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c4a2f71b71d48b5bec4e78068386c1e",
            "placeholder": "​",
            "style": "IPY_MODEL_0706c1224c2e4534af8fd4f82485c366",
            "value": "Map: 100%"
          }
        },
        "df51169e8b4843ef8f668633ad48b6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac6930c9dc4d41eaa64818d880317776",
            "max": 26332,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_897764c7f53b4ae5acb492c77c25111e",
            "value": 26332
          }
        },
        "3209b39cfd0a4c06a32c4678656695cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e06e47c8ddcc4ddabbade286d601cdde",
            "placeholder": "​",
            "style": "IPY_MODEL_6e876ebd5a2f46999cbd2633afe0e857",
            "value": " 26332/26332 [00:06&lt;00:00, 4123.83 examples/s]"
          }
        },
        "b2b69288b7964da6b2b84f565d557b78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c4a2f71b71d48b5bec4e78068386c1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0706c1224c2e4534af8fd4f82485c366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac6930c9dc4d41eaa64818d880317776": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "897764c7f53b4ae5acb492c77c25111e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e06e47c8ddcc4ddabbade286d601cdde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e876ebd5a2f46999cbd2633afe0e857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e4224f1868b40d4a12baae5347b279a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ccf33920c7e43ef94a73e95ca7ffe30",
              "IPY_MODEL_2e4493ed9dbc4cbbabe65e54d8051110",
              "IPY_MODEL_f963715530a144f89d68eb8373265927"
            ],
            "layout": "IPY_MODEL_ba12c07f21f9433c82e297dd1e4e9ce2"
          }
        },
        "9ccf33920c7e43ef94a73e95ca7ffe30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37bab71f3586458b9ca74eea350e6c3f",
            "placeholder": "​",
            "style": "IPY_MODEL_76e7386c692b4ea78d1b356bdab3d460",
            "value": "Map: 100%"
          }
        },
        "2e4493ed9dbc4cbbabe65e54d8051110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fe8c3ce54504519a6a30f17ed3b9422",
            "max": 240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5bd69563899847e59544f5b2e0bb6c88",
            "value": 240
          }
        },
        "f963715530a144f89d68eb8373265927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5ab558c92a24487b23b0e6968b6d3aa",
            "placeholder": "​",
            "style": "IPY_MODEL_c469881d76744244ba79a8a8833dd5a4",
            "value": " 240/240 [00:00&lt;00:00, 2434.94 examples/s]"
          }
        },
        "ba12c07f21f9433c82e297dd1e4e9ce2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37bab71f3586458b9ca74eea350e6c3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76e7386c692b4ea78d1b356bdab3d460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fe8c3ce54504519a6a30f17ed3b9422": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bd69563899847e59544f5b2e0bb6c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5ab558c92a24487b23b0e6968b6d3aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c469881d76744244ba79a8a8833dd5a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}